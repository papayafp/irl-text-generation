{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsKFg7hOWAoz"
      },
      "source": [
        "%%bash\n",
        "git clone https://github.com/ronakdm/irl-text-generation.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHCCuMbdWDZs"
      },
      "source": [
        "%%bash\n",
        "cd irl-text-generation/\n",
        "git pull\n",
        "cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxAHp714WDdQ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlQ7OnBQWDg0"
      },
      "source": [
        "%%bash\r\n",
        "pip install transformers\r\n",
        "pip install wandb\r\n",
        "import wandb\r\n",
        "wandb.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB4YQMmNWGo0"
      },
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from IPython import display\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"irl-text-generation/imagecoco/\")\n",
        "from coco_dataset import COCOImageCaptionsDataset\n",
        "from generator import Generator\n",
        "from rewarder import Rewarder\n",
        "from utils import save"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXO2RnAeWGyq"
      },
      "source": [
        "#########################################################################################\n",
        "#  Hyper-parameters\n",
        "#########################################################################################\n",
        "# Constants\n",
        "vocab_size = 4839\n",
        "\n",
        "# General parameters\n",
        "SEQ_LENGTH = 32\n",
        "\n",
        "# Model parameters\n",
        "g_hidden_state_size = 768\n",
        "r_hidden_state_size = 128\n",
        "action_embed_dim = 32\n",
        "\n",
        "\n",
        "# Generator training step parameters\n",
        "generator_batch_size = 32\n",
        "roll_num = 4\n",
        "\n",
        "# Rewarder training step parameters\n",
        "real_batch_size = 32\n",
        "generated_batch_size = 32\n",
        "\n",
        "# Training parameters\n",
        "G_LEARNING_RATE = 5e-5\n",
        "R_LEARNING_RATE = 0.001\n",
        "G_CLIP_MAX_NORM = 1.0\n",
        "R_CLIP_MAX_NORM = 1.0\n",
        "R_MOMENTUM = 0.9\n",
        "NUM_ITERS = 100\n",
        "G_ITERS = 1\n",
        "R_ITERS = 5\n",
        "PRETRAIN_ITERS = 120\n",
        "restore = False\n",
        "\n",
        "# TODO: Change this to the folder in your drive.\n",
        "save_dir = \"/content/gdrive/My Drive/irl-text-generation/checkpoints\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cWjWh0rWG9Y"
      },
      "source": [
        "#########################################################################################\n",
        "#  Initialization and Pretraining\n",
        "#########################################################################################\n",
        "\n",
        "str_map = pickle.load(open(\"irl-text-generation/imagecoco/save/str_map.pkl\", \"rb\"))\n",
        "\n",
        "# Load models\n",
        "generator = Generator(SEQ_LENGTH, str_map, G_CLIP_MAX_NORM)\n",
        "rewarder = Rewarder(\n",
        "    SEQ_LENGTH,\n",
        "    vocab_size,\n",
        "    g_hidden_state_size,\n",
        "    action_embed_dim,\n",
        "    r_hidden_state_size,\n",
        "    R_LEARNING_RATE,\n",
        "    R_CLIP_MAX_NORM,\n",
        "    R_MOMENTUM,\n",
        "    baseline=True\n",
        ")\n",
        "if restore:\n",
        "    # TODO: Replace this with the path to the model you want to restore.\n",
        "    print(\"Restored models\")\n",
        "    generator.restore_model(\"/content/gdrive/My Drive/irl-text-generation/checkpoints/generator_60_-50228096.0.pt\")\n",
        "    rewarder.restore_model(\"/content/gdrive/My Drive/irl-text-generation/checkpoints/rewarder_60_-415776.45625.pt\")\n",
        "\n",
        "# Load training data\n",
        "train_data = COCOImageCaptionsDataset(\"irl-text-generation/imagecoco/save/train_data.pkl\")\n",
        "train_dataloader = DataLoader(train_data, batch_size=real_batch_size, shuffle=True)\n",
        "\n",
        "# Pretrain generator\n",
        "print(\"Pretraining generator\")\n",
        "pretrain_losses = []\n",
        "for it in range(PRETRAIN_ITERS):\n",
        "    batch_data = next(iter(train_dataloader))\n",
        "    loss = generator.pretrain_step(batch_data).data.cpu().numpy()\n",
        "    pretrain_losses.append(loss)\n",
        "\n",
        "\n",
        "plt.plot(np.arange(len(pretrain_losses)), np.array(pretrain_losses))\n",
        "plt.show()\n",
        "\n",
        "g_losses = []\n",
        "r_losses = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3fIuG50WKt5"
      },
      "source": [
        "#########################################################################################\n",
        "#  Main Training Loop\n",
        "#########################################################################################\n",
        "\n",
        "try:\n",
        "  for it in range(NUM_ITERS):\n",
        "\n",
        "      # TRAIN GENERATOR\n",
        "      start = time.time()\n",
        "      loss_sum = 0\n",
        "      for g_it in range(G_ITERS):\n",
        "          g_loss = generator.rl_train_step(\n",
        "              rewarder, generator_batch_size\n",
        "          )\n",
        "          loss_sum += g_loss\n",
        "      speed = time.time() - start\n",
        "      g_losses.append(loss_sum / G_ITERS)\n",
        "      print(\n",
        "          \"MaxentPolicy Gradient {} iteration, Speed:{:.3f}, Loss:{:.3f}\".format(\n",
        "              it, speed, g_loss\n",
        "          )\n",
        "      )\n",
        "\n",
        "\n",
        "      # TRAIN REWARDER\n",
        "      start = time.time()\n",
        "      loss_sum = 0\n",
        "      for r_it in range(R_ITERS):\n",
        "          real_trajectories = next(iter(train_dataloader))\n",
        "          r_loss = rewarder.train_step(real_trajectories[0], generator, generated_batch_size)\n",
        "          loss_sum += r_loss\n",
        "      speed = time.time() - start\n",
        "      r_losses.append(loss_sum / R_ITERS)\n",
        "      print(\n",
        "          \"Reward training {} iteration, Speed:{:.3f}, Loss:{:.3f}\".format(\n",
        "              it, speed, r_loss\n",
        "          )\n",
        "      )\n",
        "\n",
        "\n",
        "      # Logging\n",
        "      if it % 5 == 0 or it == NUM_ITERS - 1 or it == 1:\n",
        "          # Save models\n",
        "          torch.save(generator.model.state_dict(), f\"{save_dir}/generator_{it}_{g_losses[-1]}.pt\")\n",
        "          torch.save(rewarder.model.state_dict(), f\"{save_dir}/rewarder_{it}_{r_losses[-1]}.pt\")\n",
        "\n",
        "          # Generate samples\n",
        "          generated_samples = generator.generate(generator_batch_size, 1, None, False, False, True)\n",
        "          output_file = f\"{save_dir}/generator_sample_{it}.txt\"\n",
        "          with open(output_file, 'w+') as fout:\n",
        "              for sentence in generated_samples[0]:\n",
        "                  buffer = ' '.join(sentence) + \"\\n\"\n",
        "                  fout.write(buffer)\n",
        "\n",
        "          # Plot loss\n",
        "          display.clear_output(wait=True)\n",
        "          fig, ax = plt.subplots(1,2,figsize=(14,7))\n",
        "          ax[0].cla(); ax[0].plot(g_losses)\n",
        "          ax[1].cla(); ax[1].plot(r_losses)\n",
        "          display.display(plt.gcf())\n",
        "          print(it, g_losses, r_losses)\n",
        "except KeyboardInterrupt:\n",
        "  print('Graceful Exit')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOiOZn8YWHHt"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}